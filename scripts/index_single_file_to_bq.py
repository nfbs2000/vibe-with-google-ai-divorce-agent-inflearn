#!/usr/bin/env python3
"""
[ìœ í‹¸ë¦¬í‹°] ë‹¨ê±´ íŒŒì¼ BigQuery ì ì¬ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì „ì²´ ë°°ì¹˜ê°€ ì•„ë‹Œ, 'íŠ¹ì • JSON íŒŒì¼ í•˜ë‚˜ë§Œ' ì½• ì§‘ì–´ì„œ BigQueryì— ë„£ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
ì£¼ë¡œ ë””ë²„ê¹… ìš©ë„ë‚˜, íŠ¹ì • íŒë¡€ë§Œ ì—…ë°ì´íŠ¸í•´ì•¼ í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

ì£¼ì˜: BigQueryì˜ Streaming Buffer ì œì•½ ë•Œë¬¸ì— DELETE í›„ ë°”ë¡œ INSERT í•˜ë©´ 
      ë°ì´í„°ê°€ ì¦‰ì‹œ ì¡°íšŒë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ìµœëŒ€ 90ë¶„ ì†Œìš”)
"""
import os
import json
import logging
from google import genai
from google.genai import types
from pathlib import Path
from google.cloud import bigquery

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_env_file(filepath=".env"):
    try:
        with open(filepath, "r") as f:
            for line in f:
                if "=" in line and not line.strip().startswith("#"):
                    key, value = line.strip().split("=", 1)
                    os.environ[key.strip()] = value.strip()
    except FileNotFoundError:
        pass

load_env_file()

def index_single_file():
    # 1. ì„¤ì • (Config)
    project_id = os.getenv("GCP_PROJECT_ID") or os.getenv("GOOGLE_CLOUD_PROJECT") or "pio-test-36cf5"
    dataset_id = "divorce_analytics"
    table_id = "precedent_cases"
    api_key = os.getenv("GOOGLE_API_KEY")
    
    # 2. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    bq_client = bigquery.Client(project=project_id)
    genai_client = genai.Client(api_key=api_key)

    # 3. ëŒ€ìƒ íŒŒì¼ ì§€ì • (Target File)
    # ì›í•˜ëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ì§ì ‘ ì§€ì •í•˜ì„¸ìš”.
    target_path = Path("data/court_cases/metadata_json/239243.json")
    if not target_path.exists():
        logger.error("âŒ File not found.")
        return

    # 4. JSON ë¡œë“œ
    with open(target_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    # 5. ì„ë² ë”© ìƒì„± (Generate Embedding)
    # ë°°ì¹˜ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ í¬ë§·ì„ ì‚¬ìš©í•´ì•¼ ê²€ìƒ‰ í’ˆì§ˆì´ ìœ ì§€ë©ë‹ˆë‹¤.
    metadata_text = f"Case: {metadata.get('filename', 'Unknown')}\nSummary: {metadata.get('key_summary', '')}\nReason: {metadata.get('alimony_reason', '')}\nFault: {metadata.get('fault_type', 'Unknown')}"
    
    logger.info(f"ğŸ¤– Generating Embedding for {target_path.name}...")
    try:
        result = genai_client.models.embed_content(
            model="text-embedding-004",
            contents=metadata_text,
            config=types.EmbedContentConfig(
                task_type="RETRIEVAL_DOCUMENT", # ë¬¸ì„œ ì €ì¥ìš© íƒœìŠ¤í¬ íƒ€ì…
                title="Single Case Indexing"
            )
        )
        embedding = result.embeddings[0].values
        logger.info(f"âœ… Embedding Length: {len(embedding)}")
    except Exception as e:
        logger.error(f"ğŸ”¥ Embedding Error: {e}")
        return

    # 6. ê¸°ì¡´ í–‰ ì‚­ì œ (ì„ íƒ ì‚¬í•­)
    # BigQuery Streaming Buffer ì´ìŠˆ ë•Œë¬¸ì— ì£¼ì„ ì²˜ë¦¬í•´ë‘ì—ˆìŠµë‹ˆë‹¤.
    # ì‹¤ì‹œê°„ ìˆ˜ì •ì´ í•„ìš”í•˜ë‹¤ë©´ UPDATE/DELETE ëŒ€ì‹  ìƒˆë¡œìš´ í…Œì´ë¸”ì„ ë§Œë“œëŠ” ê²Œ ë” ë¹ ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    case_id = metadata.get('case_id', '239243')
    # query = f"DELETE FROM `{project_id}.{dataset_id}.{table_id}` WHERE case_id = '{case_id}'"
    # bq_client.query(query).result()
    # logger.info(f"ğŸ§¹ Deleted existing row for case_id: {case_id}")

    # 7. BigQuery ì ì¬ (Insert)
    row = {
        "case_id": case_id,
        "case_number": metadata.get('filename', 'Unknown'),
        "case_type": metadata.get('case_type', 'Unknown'),
        "alimony_amount": int(metadata.get('alimony_final_amount', 0)),
        "alimony_reason": metadata.get('alimony_reason', ''),
        "property_ratio_plaintiff": float(metadata.get('property_ratio_plaintiff', 0.0)),
        "marriage_duration_years": int(metadata.get('marriage_duration_years', -1)),
        "fault_type": metadata.get('fault_type', 'Unknown'),
        "summary": metadata.get('key_summary', ''),
        "has_children": metadata.get('has_children', None),
        "full_text_embedding": embedding
    }

    errors = bq_client.insert_rows_json(f"{project_id}.{dataset_id}.{table_id}", [row])
    if not errors:
        logger.info(f"ğŸ‰ Inserted {target_path.name} into BigQuery successfully!")
    else:
        logger.error(f"âš ï¸ Insert Errors: {errors}")

if __name__ == "__main__":
    index_single_file()
