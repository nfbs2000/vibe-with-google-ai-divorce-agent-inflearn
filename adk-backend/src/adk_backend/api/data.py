#!/usr/bin/env python3
"""
ë°ì´í„° ê´€ë ¨ API ë¼ìš°í„°
"""

from fastapi import APIRouter, HTTPException, Depends, Query
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional, Dict, Any
import logging
from datetime import datetime

from ..utils.bigquery_helper import BigQueryHelper

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/data", tags=["data"])

# Pydantic ëª¨ë¸ë“¤
class TableInfo(BaseModel):
    table_name: str
    description: str
    row_count: Optional[int] = None
    last_modified: Optional[datetime] = None
    table_schema: Optional[List[Dict[str, Any]]] = Field(default=None, alias="schema")

class DataSource(BaseModel):
    name: str
    display_name: str
    description: str
    table_count: int
    total_rows: Optional[int] = None
    last_updated: Optional[datetime] = None
    status: str  # 'active', 'inactive', 'error'
    error: Optional[str] = None

class QueryExecutionRequest(BaseModel):
    sql_query: str
    dry_run: Optional[bool] = False
    max_results: Optional[int] = 1000

class QueryExecutionResponse(BaseModel):
    success: bool
    data: Optional[List[Dict[str, Any]]] = None
    row_count: Optional[int] = None
    execution_time: Optional[float] = None
    error: Optional[str] = None
    query_info: Optional[Dict[str, Any]] = None

# ì˜ì¡´ì„± ì£¼ì…
def get_bigquery_helper() -> BigQueryHelper:
    """BigQuery í—¬í¼ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return BigQueryHelper()

@router.get("/sources", response_model=List[DataSource])
async def get_data_sources(
    bq_helper: BigQueryHelper = Depends(get_bigquery_helper)
):
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        List[DataSource]: ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡
    """
    try:
        logger.info("Retrieving data sources")
        
        table_map = {table["name"]: table for table in bq_helper.list_tables()}

        # ì´í˜¼ ë„ë©”ì¸ ê´€ë ¨ ì£¼ìš” í…Œì´ë¸” ì •ì˜
        definitions = [
            {
                "name": "precedent_cases",
                "display_name": "ğŸ›ï¸ ì „êµ­ ì´í˜¼ íŒë¡€ ë°ì´í„°",
                "description": "ê³¼ê±° ì´í˜¼ íŒê²° í†µê³„, ìœ„ìë£Œ/ì¬ì‚°ë¶„í•  ì•¡ìˆ˜, ì–‘ìœ¡ê¶Œ íŒê²° ê²°ê³¼",
                "tables": ["precedent_cases"]
            },
            {
                "name": "divorce_evidence_templates",
                "display_name": "ï¿½ ì´í˜¼ ì¦ê±° ì„œì‹ ë° ê°€ì´ë“œ",
                "description": "ì†Œì¥ ì‘ì„± ì˜ˆì‹œ, í•©ë²•ì  ì¦ê±° ìˆ˜ì§‘ ê°€ì´ë“œ ë° ì„œì‹ ë°ì´í„°",
                "tables": ["divorce_evidence_templates"]
            },
            {
                "name": "counseling_knowledge_base",
                "display_name": "ğŸ“š ì „ë¬¸ ìƒë‹´ ì§€ì‹ë² ì´ìŠ¤",
                "description": "ê°€ì‚¬ ì†Œì†¡ ê´€ë ¨ FAQ, ë²•ë¥  ìš©ì–´ ì‚¬ì „, ì ˆì°¨ ì•ˆë‚´ ì •ë³´",
                "tables": ["knowledge_base"]
            }
        ]

        data_sources: List[DataSource] = []

        for definition in definitions:
            total_rows = 0
            last_updated: Optional[datetime] = None
            available_tables = 0

            for table_name in definition["tables"]:
                table_info = bq_helper.get_table_info(table_name)
                if table_info:
                    available_tables += 1
                    total_rows += table_info.get("num_rows", 0)
                    timestamp_str = table_info.get("modified") or table_info.get("created")
                    if timestamp_str:
                        try:
                            timestamp = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
                        except ValueError:
                            timestamp = None
                        if timestamp and (last_updated is None or timestamp > last_updated):
                            last_updated = timestamp

            permission_error = bq_helper.permission_error
            status = "active" if available_tables > 0 else ("error" if permission_error else "inactive")
            error_message = bq_helper.last_error if status == "error" else None

            data_sources.append(
                DataSource(
                    name=definition["name"],
                    display_name=definition["display_name"],
                    description=definition["description"],
                    table_count=len(definition["tables"]),
                    total_rows=total_rows,
                    last_updated=last_updated,
                    status=status,
                    error=error_message
                )
            )

        # ì¡´ì¬í•˜ëŠ”ë° ì •ì˜ë˜ì§€ ì•Šì€ í…Œì´ë¸”ë„ ë…¸ì¶œ
        defined_tables = {table for d in definitions for table in d["tables"]}
        for table_name, table_info in table_map.items():
            if table_name in defined_tables:
                continue
            metadata = bq_helper.get_table_info(table_name) or {}
            permission_error = bq_helper.permission_error
            error_message = bq_helper.last_error if permission_error else None
            timestamp_str = metadata.get("modified") or metadata.get("created")
            last_updated = None
            if timestamp_str:
                try:
                    last_updated = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
                except ValueError:
                    last_updated = None

            data_sources.append(
                DataSource(
                    name=table_name,
                    display_name=table_name,
                    description=f"{table_name} í…Œì´ë¸”",
                    table_count=1,
                    total_rows=metadata.get("num_rows", 0),
                    last_updated=last_updated,
                    status="error" if permission_error else "active",
                    error=error_message
                )
            )

        if bq_helper.permission_error:
            logger.warning("One or more data sources are unavailable due to BigQuery permission issues.")

        return data_sources
        
    except Exception as e:
        logger.error(f"Error retrieving data sources: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë°ì´í„° ì†ŒìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/tables", response_model=List[TableInfo])
async def get_tables(
    bq_helper: BigQueryHelper = Depends(get_bigquery_helper)
):
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸” ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        List[TableInfo]: í…Œì´ë¸” ì •ë³´ ëª©ë¡
    """
    try:
        logger.info("Retrieving table list")
        
        tables = bq_helper.list_tables()
        table_infos = []
        
        for table in tables:
            table_name = table.get("name")
            if not table_name:
                continue
            try:
                table_info = bq_helper.get_table_info(table_name) or {}
                schema_info = bq_helper.get_table_schema(table_name) or {}
                
                table_infos.append(TableInfo(
                    table_name=table_name,
                    description=table_info.get("description") or f"{table_name} í…Œì´ë¸”",
                    row_count=table_info.get('num_rows'),
                    last_modified=datetime.fromisoformat(table_info["modified"].replace("Z", "+00:00")) if table_info.get("modified") else None,
                    table_schema=schema_info.get("columns") if schema_info else None
                ))
                
            except Exception as e:
                logger.warning(f"Could not get info for table {table_name}: {e}")
                table_infos.append(TableInfo(
                    table_name=table_name,
                    description=f"{table_name} í…Œì´ë¸” (ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨)"
                ))
        
        return table_infos
        
    except Exception as e:
        logger.error(f"Error retrieving tables: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/tables/{table_name}/schema")
async def get_table_schema(
    table_name: str,
    bq_helper: BigQueryHelper = Depends(get_bigquery_helper)
):
    """
    íŠ¹ì • í…Œì´ë¸”ì˜ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        table_name: í…Œì´ë¸” ì´ë¦„
    
    Returns:
        í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´
    """
    try:
        logger.info(f"Retrieving schema for table: {table_name}")
        
        schema = bq_helper.get_table_schema(table_name)
        
        if not schema or "columns" not in schema:
            raise HTTPException(
                status_code=404,
                detail=f"í…Œì´ë¸” '{table_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        return {
            "table_name": table_name,
            "schema": schema,
            "field_count": len(schema["columns"])
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving schema for {table_name}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/tables/{table_name}/sample")
async def get_table_sample(
    table_name: str,
    limit: int = Query(10, ge=1, le=100),
    bq_helper: BigQueryHelper = Depends(get_bigquery_helper)
):
    """
    íŠ¹ì • í…Œì´ë¸”ì˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        table_name: í…Œì´ë¸” ì´ë¦„
        limit: ì¡°íšŒí•  í–‰ ìˆ˜ (1-100)
    
    Returns:
        ìƒ˜í”Œ ë°ì´í„°
    """
    try:
        logger.info(f"Retrieving sample data for table: {table_name}")
        
        # ìƒ˜í”Œ ì¿¼ë¦¬ ìƒì„±
        sql_query = f"""
        SELECT *
        FROM `{bq_helper.project_id}.{bq_helper.dataset_name}.{table_name}`
        LIMIT {limit}
        """
        
        # ì¿¼ë¦¬ ì‹¤í–‰
        results = bq_helper.execute_query(sql_query)
        
        return {
            "table_name": table_name,
            "sample_data": results,
            "row_count": len(results),
            "limit": limit
        }
        
    except Exception as e:
        logger.error(f"Error retrieving sample data for {table_name}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.post("/execute", response_model=QueryExecutionResponse)
async def execute_sql_query(
    request: QueryExecutionRequest,
    bq_helper: BigQueryHelper = Depends(get_bigquery_helper)
):
    """
    SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        request: ì¿¼ë¦¬ ì‹¤í–‰ ìš”ì²­
    
    Returns:
        QueryExecutionResponse: ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼
    """
    try:
        start_time = datetime.now()
        
        logger.info(f"Executing SQL query: {request.sql_query[:100]}...")
        
        # ì¿¼ë¦¬ ê²€ì¦ (ê¸°ë³¸ì ì¸ ë³´ì•ˆ ì²´í¬)
        if not request.sql_query.strip().upper().startswith('SELECT'):
            raise HTTPException(
                status_code=400,
                detail="SELECT ì¿¼ë¦¬ë§Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        
        # ë“œë¼ì´ ëŸ° ì²´í¬
        if request.dry_run:
            # TODO: ì¿¼ë¦¬ ìœ íš¨ì„± ê²€ì‚¬ë§Œ ìˆ˜í–‰
            return QueryExecutionResponse(
                success=True,
                data=None,
                row_count=0,
                execution_time=0.0,
                query_info={"dry_run": True, "query_valid": True}
            )
        
        # ì¿¼ë¦¬ ì‹¤í–‰
        results = bq_helper.execute_query(request.sql_query)
        
        # ê²°ê³¼ ì œí•œ
        if len(results) > request.max_results:
            results = results[:request.max_results]
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return QueryExecutionResponse(
            success=True,
            data=results,
            row_count=len(results),
            execution_time=execution_time,
            query_info={
                "max_results_applied": len(results) == request.max_results
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error executing SQL query: {e}")
        return QueryExecutionResponse(
            success=False,
            error=str(e),
            execution_time=(datetime.now() - start_time).total_seconds()
        )

@router.get("/stats")
async def get_data_stats(
    bq_helper: BigQueryHelper = Depends(get_bigquery_helper)
):
    """
    ë°ì´í„° í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        ë°ì´í„° í†µê³„ ì •ë³´
    """
    try:
        logger.info("Retrieving data statistics")
        
        tables = bq_helper.list_tables()
        stats = {
            "total_tables": len(tables),
            "total_rows": 0,
            "table_stats": []
        }
        
        for table in tables:
            table_name = table.get("name")
            if not table_name:
                continue
            try:
                table_info = bq_helper.get_table_info(table_name)
                row_count = table_info.get('num_rows', 0) if table_info else 0
                stats["total_rows"] += row_count
                
                stats["table_stats"].append({
                    "table_name": table_name,
                    "row_count": row_count,
                    "last_modified": table_info.get('modified') if table_info else None
                })
                
            except Exception as e:
                logger.warning(f"Could not get stats for table {table_name}: {e}")
        
        return stats
        
    except Exception as e:
        logger.error(f"Error retrieving data stats: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë°ì´í„° í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )
