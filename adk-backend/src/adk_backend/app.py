from __future__ import annotations

import asyncio
import json
import time
import os
import signal
import sys
import logging
from typing import Any, AsyncIterator, Dict, Optional
from datetime import datetime
from contextlib import asynccontextmanager

from dotenv import load_dotenv

# âš ï¸ IMPORTANT: .env íŒŒì¼ì„ ë¨¼ì € ë¡œë“œí•´ì•¼ ë‹¤ë¥¸ ëª¨ë“ˆì˜ configê°€ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼)
# adk-backend/src/adk_backend/app.pyì—ì„œ ../../../.envë¡œ ì ‘ê·¼
project_root = os.path.join(os.path.dirname(__file__), '..', '..', '..')
dotenv_path = os.path.join(project_root, '.env')
load_dotenv(dotenv_path=dotenv_path)

# .env ë¡œë“œ í›„ ë‹¤ë¥¸ ëª¨ë“ˆ import
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from google.genai import types as genai_types
from pydantic import BaseModel, Field

from .config import get_settings
from .live import LiveRunManager, format_sse_message
from .tools.bigquery import bigquery_list_templates, bigquery_render_template
from .sessions import ensure_session
from .workflows.divorce import get_runner
from .nlp.gemini_client import initialize_gemini_client_with_cag

# API ë¼ìš°í„° import
from .api import chat, data, system

# ë¡œê¹… ì„¤ì • import
from .utils.logging_config import setup_logging
from .middleware.logging_middleware import RequestLoggingMiddleware

# ë¡œê¹… ì´ˆê¸°í™”
log_level = os.getenv("LOG_LEVEL", "INFO")
setup_logging(level=log_level, enable_colors=True)
logger = logging.getLogger(__name__)


# Signal handler for graceful shutdown
def handle_shutdown_signal(signum, frame):
    """Ctrl+C (SIGINT) ë° SIGTERM ì‹ í˜¸ë¥¼ ê¹”ë”í•˜ê²Œ ì²˜ë¦¬"""
    logger.info("\n" + "="*80)
    logger.info("ğŸ›‘ Shutdown signal received. Cleaning up...")
    logger.info("="*80)
    sys.exit(0)


# Register signal handlers
signal.signal(signal.SIGINT, handle_shutdown_signal)
signal.signal(signal.SIGTERM, handle_shutdown_signal)


# Lifespan context manager
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ë° ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸"""
    # Startup
    logger.info("=" * 80)
    logger.info("ğŸš€ Unified Divorce Intelligence Platform Starting...")
    settings = get_settings()
    logger.info(f"ğŸ“Š Project: {settings.google_project_id}")
    logger.info(f"ğŸ“ Log Level: {log_level}")
    logger.info("=" * 80)

    # 1. CAG ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    logger.info("ğŸ“š CAG (Context-Augmented Generation) ì´ˆê¸°í™” ì¤‘...")
    try:
        initialize_gemini_client_with_cag()
        logger.info("âœ… CAG ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë“  ì‚¬ìš©ìê°€ Context Cacheë¥¼ ê³µìœ í•©ë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"âŒ CAG ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

    yield

    # Shutdown
    logger.info("=" * 80)
    logger.info("ğŸ‘‹ Unified Divorce Intelligence Platform Shutting down...")
    logger.info("=" * 80)


app = FastAPI(
    title="Unified Divorce Intelligence Platform",
    description="Gemini ë©€í‹°ëª¨ë‹¬ AIì™€ BigQuery ê¸°ë°˜ì˜ í†µí•© ì´í˜¼ ì†”ë£¨ì…˜ í”Œë«í¼",
    version="1.0.0",
    lifespan=lifespan
)
settings = get_settings()
live_manager = LiveRunManager()

# CORS ì„¤ì •
origins = [
    "http://localhost:3000",  # React ê°œë°œ ì„œë²„
    "http://localhost:5173",  # Vite ê°œë°œ ì„œë²„
    "http://localhost:8005",  # Frontend ì„œë²„
    "http://localhost:8006",  # AI Phishing Frontend
    "http://127.0.0.1:3000",
    "http://127.0.0.1:5173",
    "http://127.0.0.1:8005",
    "http://127.0.0.1:8006",
]

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì¶”ê°€ origins ë¡œë“œ
if os.getenv('CORS_ORIGINS'):
    additional_origins = os.getenv('CORS_ORIGINS').split(',')
    origins.extend([origin.strip() for origin in additional_origins])

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¡œê¹… ë¯¸ë“¤ì›¨ì–´ ë“±ë¡
app.add_middleware(RequestLoggingMiddleware)

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì • (ì—…ë¡œë“œëœ íŒŒì¼ ì ‘ê·¼ìš©)
# ì£¼ì˜: í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” Nginx/Apache ë“±ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë¨
upload_dir = os.path.join(os.getcwd(), "data", "uploads")
os.makedirs(upload_dir, exist_ok=True)
app.mount("/uploads", StaticFiles(directory=upload_dir), name="uploads")

# API ë¼ìš°í„° ë“±ë¡
app.include_router(chat.router, prefix="/api")
app.include_router(data.router, prefix="/api")
app.include_router(system.router, prefix="/api")


class RunRequest(BaseModel):
    prompt: str = Field(..., description="ì‚¬ìš©ì ì§ˆë¬¸")
    user_id: Optional[str] = None
    session_id: Optional[str] = None


def _serialize_event(event: Any) -> Dict[str, Any]:
    try:
        payload = event.model_dump(by_alias=True, exclude_none=True)
    except AttributeError:  # pragma: no cover - defensive
        payload = json.loads(json.dumps(event, default=str))
    payload["_meta"] = {"timestamp": time.time()}
    return payload


async def _run_once(request: RunRequest) -> Dict[str, Any]:
    runner = get_runner()
    session = await ensure_session(request.user_id, request.session_id)
    message = genai_types.Content(role="user", parts=[genai_types.Part(text=request.prompt)])
    events = []
    async for event in runner.run_async(
        user_id=session.user_id,
        session_id=session.id,
        new_message=message,
    ):
        events.append(_serialize_event(event))
    return {"session_id": session.id, "events": events}


# ê¸°ë³¸ ë¼ìš°íŠ¸
@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "Unified Divorce Intelligence API",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs",
        "health": "/api/system/health"
    }

@app.get("/health")
async def health() -> Dict[str, str]:
    return {"status": "ok", "project": settings.google_project_id}

# ë ˆê±°ì‹œ í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (í•˜ìœ„ í˜¸í™˜ì„±)
@app.get("/api/health")
async def legacy_health_check():
    """ë ˆê±°ì‹œ í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (ë¦¬ë‹¤ì´ë ‰íŠ¸)"""
    return {
        "status": "healthy",
        "timestamp": datetime.now(),
        "version": "1.0.0",
        "message": "Use /api/system/health for detailed health information"
    }


@app.post("/api/run")
async def run(request: RunRequest) -> JSONResponse:
    if not request.prompt:
        raise HTTPException(status_code=400, detail="prompt is required")
    result = await _run_once(request)
    return JSONResponse(result)


class LiveRunRequest(BaseModel):
    prompt: str = Field(..., description="ì‚¬ìš©ì ì§ˆë¬¸")
    user_id: Optional[str] = None
    session_id: Optional[str] = None


class LiveRunResponse(BaseModel):
    run_id: str
    session_id: str


@app.post("/api/live/run", response_model=LiveRunResponse)
async def live_run(request: LiveRunRequest) -> LiveRunResponse:
    if not request.prompt:
        raise HTTPException(status_code=400, detail="prompt is required")
    run_id, session_id = await live_manager.start_run(
        prompt=request.prompt,
        user_id=request.user_id,
        session_id=request.session_id,
    )
    return LiveRunResponse(run_id=run_id, session_id=session_id)


@app.get("/api/live/events")
async def stream_events(run_id: str, request: Request):
    if not run_id:
        raise HTTPException(status_code=400, detail="run_id is required")
    try:
        queue = await live_manager.subscribe(run_id)
    except KeyError as exc:
        raise HTTPException(status_code=404, detail=str(exc)) from exc

    async def event_generator() -> AsyncIterator[str]:
        try:
            while True:
                if await request.is_disconnected():
                    break
                try:
                    message = await asyncio.wait_for(queue.get(), timeout=15.0)
                    yield format_sse_message(message)
                except asyncio.TimeoutError:
                    yield "event: keepalive\ndata: {}\n\n"
        finally:
            await live_manager.unsubscribe(run_id, queue)

    return StreamingResponse(event_generator(), media_type="text/event-stream")


@app.get("/api/templates")
async def list_templates() -> Dict[str, Any]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ BigQuery í…œí”Œë¦¿ ëª©ë¡ì„ ë°˜í™˜."""
    result_json = bigquery_list_templates()
    return json.loads(result_json)


class RenderTemplateRequest(BaseModel):
    template_id: str = Field(..., description="í…œí”Œë¦¿ ID")
    params: Optional[Dict[str, Any]] = Field(default=None, description="í…œí”Œë¦¿ íŒŒë¼ë¯¸í„°")
    dry_run: bool = False
    project_id: Optional[str] = None


@app.post("/api/templates/render")
async def render_template(request: RenderTemplateRequest) -> Dict[str, Any]:
    """BigQuery í…œí”Œë¦¿ì„ ë Œë”ë§."""
    params_json = json.dumps(request.params) if request.params else None
    result_json = bigquery_render_template(
        template_id=request.template_id,
        params_json=params_json,
        dry_run=request.dry_run,
        project_id=request.project_id,
    )
    return json.loads(result_json)
